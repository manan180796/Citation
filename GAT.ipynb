{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjYEjVt37E22nuPfsHgv/k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manan180796/Citation/blob/main/GAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ympVvjeWNCV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDDKR7iGTLZK",
        "outputId": "83e5727d-6878-4c46-af1f-2766d7fe7ca6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install spektral"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spektral\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/55/de193ea0b63b2bacb4e60298856e45cff6dd3e63aa49e8b3069d7a44b840/spektral-0.6.2-py3-none-any.whl (95kB)\n",
            "\r\u001b[K     |███▍                            | 10kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 20kB 16.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 30kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 40kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 51kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 61kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 71kB 11.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 81kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 92kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from spektral) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from spektral) (1.1.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from spektral) (4.2.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from spektral) (0.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from spektral) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from spektral) (1.18.5)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from spektral) (2.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from spektral) (2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from spektral) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->spektral) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->spektral) (2018.9)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (2.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (0.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.33.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (2.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.12.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (0.35.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->spektral) (1.1.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->spektral) (4.4.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->spektral) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->spektral) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->spektral) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->spektral) (2020.6.20)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (3.3.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (50.3.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (2.0.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->spektral) (3.4.0)\n",
            "Installing collected packages: spektral\n",
            "Successfully installed spektral-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-JXK8-wTBQB"
      },
      "source": [
        "This example implements the experiments on citation networks from the paper:\n",
        "Graph Attention Networks (https://arxiv.org/abs/1710.10903)\n",
        "Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, Yoshua Bengio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ugLQwvESr3h"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Input, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from spektral.datasets import citation\n",
        "from spektral.layers import GraphAttention"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqbYdk_wTaAc",
        "outputId": "fda9006b-3cb3-4064-d30a-e2a6c12f00f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# Load data\n",
        "dataset = 'cora'\n",
        "A, X, y, train_mask, val_mask, test_mask = citation.load_data(dataset)\n",
        "\n",
        "# Parameters\n",
        "channels = 8            # Number of channel in each head of the first GAT layer\n",
        "n_attn_heads = 8        # Number of attention heads in first GAT layer\n",
        "N = X.shape[0]          # Number of nodes in the graph\n",
        "F = X.shape[1]          # Original size of node features\n",
        "n_classes = y.shape[1]  # Number of classes\n",
        "dropout = 0.6           # Dropout rate for the features and adjacency matrix\n",
        "l2_reg = 5e-6           # L2 regularization rate\n",
        "learning_rate = 5e-3    # Learning rate\n",
        "epochs = 20000          # Number of training epochs\n",
        "es_patience = 100       # Patience for early stopping"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading cora from https://github.com/tkipf/gcn/raw/master/gcn/data/\n",
            "Loading cora dataset\n",
            "Pre-processing node features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcNQbavIUC2U"
      },
      "source": [
        "# Model definition\n",
        "X_in = Input(shape=(F, ))\n",
        "A_in = Input(shape=(N, ), sparse=True)\n",
        "\n",
        "dropout_1 = Dropout(dropout)(X_in)\n",
        "graph_attention_1 = GraphAttention(channels,\n",
        "                                   attn_heads=n_attn_heads,\n",
        "                                   concat_heads=True,\n",
        "                                   dropout_rate=dropout,\n",
        "                                   activation='elu',\n",
        "                                   kernel_regularizer=l2(l2_reg),\n",
        "                                   attn_kernel_regularizer=l2(l2_reg)\n",
        "                                   )([dropout_1, A_in])\n",
        "dropout_2 = Dropout(dropout)(graph_attention_1)\n",
        "graph_attention_2 = GraphAttention(n_classes,\n",
        "                                   attn_heads=1,\n",
        "                                   concat_heads=False,\n",
        "                                   dropout_rate=dropout,\n",
        "                                   activation='softmax',\n",
        "                                   kernel_regularizer=l2(l2_reg),\n",
        "                                   attn_kernel_regularizer=l2(l2_reg)\n",
        "                                   )([dropout_2, A_in])\n",
        "# Build model\n",
        "model = Model(inputs=[X_in, A_in], outputs=graph_attention_2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4K7gH7zUuTN",
        "outputId": "e87e4da2-4681-4d8b-c101-61dc665ce45f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "optimizer = Adam(lr=learning_rate)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              weighted_metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1433)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1433)         0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2708)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "graph_attention (GraphAttention (None, 64)           91904       dropout[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 64)           0           graph_attention[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "graph_attention_1 (GraphAttenti (None, 7)            469         dropout_1[0][0]                  \n",
            "                                                                 input_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 92,373\n",
            "Trainable params: 92,373\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULNjGNJoZnoL"
      },
      "source": [
        "# Preprocessing operations\n",
        "A = A.astype('f4')\n",
        "X = X.toarray()\n",
        "validation_data = ([X, A], y, val_mask)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swGIVzMbUygz",
        "outputId": "3abed5bb-7d3b-4ec7-9cbf-bd1103fcd89a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "model.fit([X, A],\n",
        "          y,\n",
        "          sample_weight=train_mask,\n",
        "          epochs=epochs,\n",
        "          batch_size=N,\n",
        "          validation_data=validation_data,\n",
        "          shuffle=False,  # Shuffling data means shuffling the whole graph\n",
        "          callbacks=[\n",
        "              EarlyStopping(patience=es_patience, restore_best_weights=True)\n",
        "          ])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 947ms/step - loss: 0.1007 - acc: 0.1643 - val_loss: 0.3595 - val_acc: 0.2040\n",
            "Epoch 2/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.1006 - acc: 0.2071 - val_loss: 0.3593 - val_acc: 0.2200\n",
            "Epoch 3/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.1005 - acc: 0.3000 - val_loss: 0.3590 - val_acc: 0.2380\n",
            "Epoch 4/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.1005 - acc: 0.3286 - val_loss: 0.3584 - val_acc: 0.2040\n",
            "Epoch 5/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.1003 - acc: 0.3571 - val_loss: 0.3580 - val_acc: 0.3860\n",
            "Epoch 6/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.1002 - acc: 0.3214 - val_loss: 0.3576 - val_acc: 0.5880\n",
            "Epoch 7/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.1003 - acc: 0.2857 - val_loss: 0.3573 - val_acc: 0.6340\n",
            "Epoch 8/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0999 - acc: 0.4286 - val_loss: 0.3570 - val_acc: 0.6540\n",
            "Epoch 9/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0998 - acc: 0.4071 - val_loss: 0.3569 - val_acc: 0.6440\n",
            "Epoch 10/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0997 - acc: 0.5000 - val_loss: 0.3567 - val_acc: 0.5920\n",
            "Epoch 11/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0995 - acc: 0.5000 - val_loss: 0.3566 - val_acc: 0.5560\n",
            "Epoch 12/20000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0994 - acc: 0.6071 - val_loss: 0.3563 - val_acc: 0.5660\n",
            "Epoch 13/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0990 - acc: 0.6000 - val_loss: 0.3559 - val_acc: 0.5640\n",
            "Epoch 14/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0990 - acc: 0.5714 - val_loss: 0.3555 - val_acc: 0.5620\n",
            "Epoch 15/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0986 - acc: 0.6214 - val_loss: 0.3549 - val_acc: 0.5840\n",
            "Epoch 16/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0986 - acc: 0.6000 - val_loss: 0.3542 - val_acc: 0.6600\n",
            "Epoch 17/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0984 - acc: 0.5643 - val_loss: 0.3535 - val_acc: 0.7120\n",
            "Epoch 18/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0974 - acc: 0.6429 - val_loss: 0.3526 - val_acc: 0.7380\n",
            "Epoch 19/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0976 - acc: 0.6429 - val_loss: 0.3516 - val_acc: 0.7460\n",
            "Epoch 20/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0975 - acc: 0.6286 - val_loss: 0.3506 - val_acc: 0.7640\n",
            "Epoch 21/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0969 - acc: 0.6429 - val_loss: 0.3498 - val_acc: 0.7660\n",
            "Epoch 22/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0960 - acc: 0.7143 - val_loss: 0.3488 - val_acc: 0.7560\n",
            "Epoch 23/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0968 - acc: 0.6071 - val_loss: 0.3480 - val_acc: 0.7440\n",
            "Epoch 24/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0963 - acc: 0.6786 - val_loss: 0.3470 - val_acc: 0.7440\n",
            "Epoch 25/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0952 - acc: 0.6786 - val_loss: 0.3460 - val_acc: 0.7360\n",
            "Epoch 26/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0948 - acc: 0.6643 - val_loss: 0.3449 - val_acc: 0.7300\n",
            "Epoch 27/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0946 - acc: 0.6857 - val_loss: 0.3437 - val_acc: 0.7280\n",
            "Epoch 28/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0937 - acc: 0.7000 - val_loss: 0.3425 - val_acc: 0.7400\n",
            "Epoch 29/20000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0931 - acc: 0.7071 - val_loss: 0.3412 - val_acc: 0.7540\n",
            "Epoch 30/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0936 - acc: 0.6857 - val_loss: 0.3399 - val_acc: 0.7540\n",
            "Epoch 31/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0915 - acc: 0.7357 - val_loss: 0.3385 - val_acc: 0.7580\n",
            "Epoch 32/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0927 - acc: 0.7000 - val_loss: 0.3373 - val_acc: 0.7600\n",
            "Epoch 33/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0907 - acc: 0.7143 - val_loss: 0.3360 - val_acc: 0.7540\n",
            "Epoch 34/20000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0919 - acc: 0.7357 - val_loss: 0.3344 - val_acc: 0.7600\n",
            "Epoch 35/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0907 - acc: 0.6929 - val_loss: 0.3327 - val_acc: 0.7780\n",
            "Epoch 36/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0900 - acc: 0.7071 - val_loss: 0.3308 - val_acc: 0.7900\n",
            "Epoch 37/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0897 - acc: 0.7500 - val_loss: 0.3288 - val_acc: 0.7980\n",
            "Epoch 38/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0888 - acc: 0.7143 - val_loss: 0.3269 - val_acc: 0.7980\n",
            "Epoch 39/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0865 - acc: 0.7714 - val_loss: 0.3249 - val_acc: 0.8000\n",
            "Epoch 40/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0871 - acc: 0.7643 - val_loss: 0.3230 - val_acc: 0.7940\n",
            "Epoch 41/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0850 - acc: 0.7214 - val_loss: 0.3209 - val_acc: 0.7940\n",
            "Epoch 42/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0865 - acc: 0.7000 - val_loss: 0.3191 - val_acc: 0.7940\n",
            "Epoch 43/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0855 - acc: 0.7857 - val_loss: 0.3173 - val_acc: 0.7920\n",
            "Epoch 44/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0816 - acc: 0.7571 - val_loss: 0.3153 - val_acc: 0.7960\n",
            "Epoch 45/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0822 - acc: 0.7286 - val_loss: 0.3132 - val_acc: 0.8000\n",
            "Epoch 46/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0827 - acc: 0.7643 - val_loss: 0.3111 - val_acc: 0.7960\n",
            "Epoch 47/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0811 - acc: 0.7714 - val_loss: 0.3091 - val_acc: 0.7980\n",
            "Epoch 48/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0807 - acc: 0.7286 - val_loss: 0.3070 - val_acc: 0.7960\n",
            "Epoch 49/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0801 - acc: 0.7500 - val_loss: 0.3048 - val_acc: 0.7900\n",
            "Epoch 50/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0818 - acc: 0.7143 - val_loss: 0.3027 - val_acc: 0.7940\n",
            "Epoch 51/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0785 - acc: 0.7714 - val_loss: 0.3002 - val_acc: 0.7920\n",
            "Epoch 52/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0775 - acc: 0.7286 - val_loss: 0.2980 - val_acc: 0.7940\n",
            "Epoch 53/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0773 - acc: 0.7786 - val_loss: 0.2957 - val_acc: 0.7900\n",
            "Epoch 54/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0778 - acc: 0.7500 - val_loss: 0.2938 - val_acc: 0.7940\n",
            "Epoch 55/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0739 - acc: 0.7714 - val_loss: 0.2918 - val_acc: 0.7940\n",
            "Epoch 56/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0740 - acc: 0.8000 - val_loss: 0.2897 - val_acc: 0.7900\n",
            "Epoch 57/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0757 - acc: 0.7571 - val_loss: 0.2873 - val_acc: 0.7900\n",
            "Epoch 58/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0741 - acc: 0.7786 - val_loss: 0.2851 - val_acc: 0.7900\n",
            "Epoch 59/20000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0731 - acc: 0.8071 - val_loss: 0.2828 - val_acc: 0.7900\n",
            "Epoch 60/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0731 - acc: 0.7214 - val_loss: 0.2803 - val_acc: 0.7940\n",
            "Epoch 61/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0696 - acc: 0.7786 - val_loss: 0.2779 - val_acc: 0.7960\n",
            "Epoch 62/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0699 - acc: 0.7857 - val_loss: 0.2754 - val_acc: 0.7940\n",
            "Epoch 63/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0718 - acc: 0.7286 - val_loss: 0.2726 - val_acc: 0.7920\n",
            "Epoch 64/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0707 - acc: 0.7429 - val_loss: 0.2698 - val_acc: 0.7940\n",
            "Epoch 65/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0688 - acc: 0.7429 - val_loss: 0.2667 - val_acc: 0.8080\n",
            "Epoch 66/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0670 - acc: 0.7786 - val_loss: 0.2637 - val_acc: 0.8040\n",
            "Epoch 67/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0664 - acc: 0.7857 - val_loss: 0.2607 - val_acc: 0.8040\n",
            "Epoch 68/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0632 - acc: 0.7857 - val_loss: 0.2581 - val_acc: 0.8040\n",
            "Epoch 69/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0634 - acc: 0.7929 - val_loss: 0.2555 - val_acc: 0.8040\n",
            "Epoch 70/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0678 - acc: 0.7786 - val_loss: 0.2532 - val_acc: 0.8000\n",
            "Epoch 71/20000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0637 - acc: 0.8143 - val_loss: 0.2508 - val_acc: 0.7980\n",
            "Epoch 72/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0640 - acc: 0.7929 - val_loss: 0.2485 - val_acc: 0.7960\n",
            "Epoch 73/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0628 - acc: 0.8071 - val_loss: 0.2465 - val_acc: 0.7920\n",
            "Epoch 74/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0646 - acc: 0.7857 - val_loss: 0.2444 - val_acc: 0.7980\n",
            "Epoch 75/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0602 - acc: 0.7857 - val_loss: 0.2428 - val_acc: 0.8020\n",
            "Epoch 76/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0622 - acc: 0.7786 - val_loss: 0.2410 - val_acc: 0.7980\n",
            "Epoch 77/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0611 - acc: 0.7857 - val_loss: 0.2390 - val_acc: 0.7980\n",
            "Epoch 78/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0613 - acc: 0.7714 - val_loss: 0.2369 - val_acc: 0.7980\n",
            "Epoch 79/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0609 - acc: 0.7786 - val_loss: 0.2346 - val_acc: 0.7940\n",
            "Epoch 80/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0569 - acc: 0.8071 - val_loss: 0.2320 - val_acc: 0.7980\n",
            "Epoch 81/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0631 - acc: 0.7786 - val_loss: 0.2294 - val_acc: 0.8020\n",
            "Epoch 82/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0592 - acc: 0.7857 - val_loss: 0.2272 - val_acc: 0.8040\n",
            "Epoch 83/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0591 - acc: 0.7357 - val_loss: 0.2251 - val_acc: 0.8000\n",
            "Epoch 84/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0589 - acc: 0.7929 - val_loss: 0.2230 - val_acc: 0.8000\n",
            "Epoch 85/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0511 - acc: 0.8500 - val_loss: 0.2212 - val_acc: 0.8000\n",
            "Epoch 86/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0585 - acc: 0.7643 - val_loss: 0.2194 - val_acc: 0.8000\n",
            "Epoch 87/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0567 - acc: 0.7643 - val_loss: 0.2179 - val_acc: 0.7980\n",
            "Epoch 88/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0560 - acc: 0.8286 - val_loss: 0.2164 - val_acc: 0.8020\n",
            "Epoch 89/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0621 - acc: 0.7143 - val_loss: 0.2152 - val_acc: 0.8020\n",
            "Epoch 90/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0534 - acc: 0.8071 - val_loss: 0.2142 - val_acc: 0.7960\n",
            "Epoch 91/20000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0526 - acc: 0.8286 - val_loss: 0.2133 - val_acc: 0.7900\n",
            "Epoch 92/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0522 - acc: 0.8000 - val_loss: 0.2122 - val_acc: 0.7880\n",
            "Epoch 93/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0558 - acc: 0.7929 - val_loss: 0.2110 - val_acc: 0.7900\n",
            "Epoch 94/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0562 - acc: 0.7786 - val_loss: 0.2097 - val_acc: 0.7880\n",
            "Epoch 95/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0525 - acc: 0.8071 - val_loss: 0.2080 - val_acc: 0.7880\n",
            "Epoch 96/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0499 - acc: 0.8429 - val_loss: 0.2066 - val_acc: 0.7900\n",
            "Epoch 97/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0546 - acc: 0.7786 - val_loss: 0.2050 - val_acc: 0.7920\n",
            "Epoch 98/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0552 - acc: 0.7714 - val_loss: 0.2033 - val_acc: 0.7960\n",
            "Epoch 99/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0568 - acc: 0.7500 - val_loss: 0.2017 - val_acc: 0.7960\n",
            "Epoch 100/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0536 - acc: 0.8286 - val_loss: 0.2005 - val_acc: 0.7940\n",
            "Epoch 101/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0528 - acc: 0.7857 - val_loss: 0.1991 - val_acc: 0.7900\n",
            "Epoch 102/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0498 - acc: 0.8500 - val_loss: 0.1974 - val_acc: 0.7920\n",
            "Epoch 103/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0535 - acc: 0.7857 - val_loss: 0.1956 - val_acc: 0.7920\n",
            "Epoch 104/20000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0500 - acc: 0.8143 - val_loss: 0.1937 - val_acc: 0.7960\n",
            "Epoch 105/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0510 - acc: 0.8214 - val_loss: 0.1923 - val_acc: 0.7940\n",
            "Epoch 106/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0503 - acc: 0.7571 - val_loss: 0.1909 - val_acc: 0.8000\n",
            "Epoch 107/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0533 - acc: 0.7786 - val_loss: 0.1895 - val_acc: 0.8040\n",
            "Epoch 108/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0515 - acc: 0.7643 - val_loss: 0.1884 - val_acc: 0.8040\n",
            "Epoch 109/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0515 - acc: 0.8071 - val_loss: 0.1873 - val_acc: 0.8000\n",
            "Epoch 110/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0551 - acc: 0.7357 - val_loss: 0.1864 - val_acc: 0.8020\n",
            "Epoch 111/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0456 - acc: 0.8357 - val_loss: 0.1855 - val_acc: 0.8020\n",
            "Epoch 112/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0452 - acc: 0.8214 - val_loss: 0.1846 - val_acc: 0.8000\n",
            "Epoch 113/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0499 - acc: 0.8286 - val_loss: 0.1836 - val_acc: 0.8060\n",
            "Epoch 114/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0460 - acc: 0.8429 - val_loss: 0.1825 - val_acc: 0.8060\n",
            "Epoch 115/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0468 - acc: 0.8429 - val_loss: 0.1817 - val_acc: 0.8040\n",
            "Epoch 116/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0486 - acc: 0.8214 - val_loss: 0.1807 - val_acc: 0.8020\n",
            "Epoch 117/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0473 - acc: 0.8000 - val_loss: 0.1800 - val_acc: 0.8020\n",
            "Epoch 118/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0497 - acc: 0.7929 - val_loss: 0.1794 - val_acc: 0.8040\n",
            "Epoch 119/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0546 - acc: 0.7214 - val_loss: 0.1788 - val_acc: 0.8040\n",
            "Epoch 120/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0473 - acc: 0.8214 - val_loss: 0.1785 - val_acc: 0.8040\n",
            "Epoch 121/20000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0506 - acc: 0.8071 - val_loss: 0.1785 - val_acc: 0.8040\n",
            "Epoch 122/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0521 - acc: 0.7929 - val_loss: 0.1786 - val_acc: 0.8020\n",
            "Epoch 123/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0468 - acc: 0.8143 - val_loss: 0.1787 - val_acc: 0.8000\n",
            "Epoch 124/20000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0476 - acc: 0.8071 - val_loss: 0.1785 - val_acc: 0.7960\n",
            "Epoch 125/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0519 - acc: 0.7571 - val_loss: 0.1784 - val_acc: 0.7960\n",
            "Epoch 126/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0431 - acc: 0.8429 - val_loss: 0.1776 - val_acc: 0.7980\n",
            "Epoch 127/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0450 - acc: 0.8357 - val_loss: 0.1766 - val_acc: 0.8000\n",
            "Epoch 128/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0439 - acc: 0.8071 - val_loss: 0.1753 - val_acc: 0.7980\n",
            "Epoch 129/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0412 - acc: 0.8500 - val_loss: 0.1739 - val_acc: 0.8000\n",
            "Epoch 130/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0496 - acc: 0.7643 - val_loss: 0.1728 - val_acc: 0.8040\n",
            "Epoch 131/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0429 - acc: 0.8500 - val_loss: 0.1718 - val_acc: 0.8060\n",
            "Epoch 132/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0445 - acc: 0.8571 - val_loss: 0.1706 - val_acc: 0.8000\n",
            "Epoch 133/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0431 - acc: 0.8786 - val_loss: 0.1696 - val_acc: 0.8020\n",
            "Epoch 134/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0461 - acc: 0.8143 - val_loss: 0.1687 - val_acc: 0.8020\n",
            "Epoch 135/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0468 - acc: 0.8357 - val_loss: 0.1679 - val_acc: 0.8020\n",
            "Epoch 136/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0473 - acc: 0.7786 - val_loss: 0.1667 - val_acc: 0.8060\n",
            "Epoch 137/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0455 - acc: 0.8214 - val_loss: 0.1654 - val_acc: 0.8040\n",
            "Epoch 138/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0404 - acc: 0.8786 - val_loss: 0.1643 - val_acc: 0.8020\n",
            "Epoch 139/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0406 - acc: 0.8500 - val_loss: 0.1632 - val_acc: 0.8040\n",
            "Epoch 140/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0435 - acc: 0.8643 - val_loss: 0.1624 - val_acc: 0.8020\n",
            "Epoch 141/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0518 - acc: 0.7857 - val_loss: 0.1617 - val_acc: 0.8020\n",
            "Epoch 142/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0423 - acc: 0.8000 - val_loss: 0.1609 - val_acc: 0.8000\n",
            "Epoch 143/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0453 - acc: 0.8214 - val_loss: 0.1604 - val_acc: 0.7980\n",
            "Epoch 144/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0437 - acc: 0.8214 - val_loss: 0.1600 - val_acc: 0.7980\n",
            "Epoch 145/20000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0442 - acc: 0.8143 - val_loss: 0.1597 - val_acc: 0.7960\n",
            "Epoch 146/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0427 - acc: 0.8071 - val_loss: 0.1593 - val_acc: 0.7960\n",
            "Epoch 147/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0452 - acc: 0.8357 - val_loss: 0.1588 - val_acc: 0.7980\n",
            "Epoch 148/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0451 - acc: 0.7786 - val_loss: 0.1583 - val_acc: 0.8020\n",
            "Epoch 149/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0417 - acc: 0.8357 - val_loss: 0.1577 - val_acc: 0.8060\n",
            "Epoch 150/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0463 - acc: 0.8286 - val_loss: 0.1570 - val_acc: 0.8060\n",
            "Epoch 151/20000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0483 - acc: 0.7500 - val_loss: 0.1564 - val_acc: 0.8080\n",
            "Epoch 152/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0441 - acc: 0.8143 - val_loss: 0.1555 - val_acc: 0.8120\n",
            "Epoch 153/20000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0457 - acc: 0.8357 - val_loss: 0.1549 - val_acc: 0.8120\n",
            "Epoch 154/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0507 - acc: 0.7714 - val_loss: 0.1547 - val_acc: 0.8120\n",
            "Epoch 155/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0459 - acc: 0.8286 - val_loss: 0.1548 - val_acc: 0.8120\n",
            "Epoch 156/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0452 - acc: 0.8143 - val_loss: 0.1549 - val_acc: 0.8140\n",
            "Epoch 157/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0430 - acc: 0.8500 - val_loss: 0.1547 - val_acc: 0.8140\n",
            "Epoch 158/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0445 - acc: 0.8286 - val_loss: 0.1544 - val_acc: 0.8100\n",
            "Epoch 159/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0427 - acc: 0.7857 - val_loss: 0.1542 - val_acc: 0.8080\n",
            "Epoch 160/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0450 - acc: 0.8286 - val_loss: 0.1542 - val_acc: 0.8080\n",
            "Epoch 161/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0427 - acc: 0.8357 - val_loss: 0.1542 - val_acc: 0.8020\n",
            "Epoch 162/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0440 - acc: 0.8214 - val_loss: 0.1546 - val_acc: 0.8020\n",
            "Epoch 163/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0425 - acc: 0.8143 - val_loss: 0.1550 - val_acc: 0.7960\n",
            "Epoch 164/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0404 - acc: 0.8571 - val_loss: 0.1554 - val_acc: 0.7940\n",
            "Epoch 165/20000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0420 - acc: 0.8571 - val_loss: 0.1561 - val_acc: 0.7960\n",
            "Epoch 166/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0392 - acc: 0.8214 - val_loss: 0.1567 - val_acc: 0.7960\n",
            "Epoch 167/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0376 - acc: 0.8500 - val_loss: 0.1565 - val_acc: 0.7960\n",
            "Epoch 168/20000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0408 - acc: 0.8429 - val_loss: 0.1562 - val_acc: 0.7940\n",
            "Epoch 169/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0416 - acc: 0.8071 - val_loss: 0.1557 - val_acc: 0.7920\n",
            "Epoch 170/20000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0387 - acc: 0.8500 - val_loss: 0.1549 - val_acc: 0.7920\n",
            "Epoch 171/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0448 - acc: 0.8357 - val_loss: 0.1540 - val_acc: 0.7960\n",
            "Epoch 172/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0489 - acc: 0.7714 - val_loss: 0.1529 - val_acc: 0.7940\n",
            "Epoch 173/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0388 - acc: 0.8500 - val_loss: 0.1517 - val_acc: 0.8000\n",
            "Epoch 174/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0446 - acc: 0.8071 - val_loss: 0.1508 - val_acc: 0.8060\n",
            "Epoch 175/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0450 - acc: 0.8286 - val_loss: 0.1501 - val_acc: 0.8060\n",
            "Epoch 176/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0421 - acc: 0.8000 - val_loss: 0.1498 - val_acc: 0.8100\n",
            "Epoch 177/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0415 - acc: 0.8071 - val_loss: 0.1494 - val_acc: 0.8100\n",
            "Epoch 178/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0431 - acc: 0.8071 - val_loss: 0.1491 - val_acc: 0.8100\n",
            "Epoch 179/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0451 - acc: 0.7643 - val_loss: 0.1486 - val_acc: 0.8100\n",
            "Epoch 180/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0385 - acc: 0.8500 - val_loss: 0.1484 - val_acc: 0.8100\n",
            "Epoch 181/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0451 - acc: 0.8214 - val_loss: 0.1488 - val_acc: 0.8080\n",
            "Epoch 182/20000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0429 - acc: 0.8357 - val_loss: 0.1494 - val_acc: 0.8040\n",
            "Epoch 183/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0371 - acc: 0.8786 - val_loss: 0.1498 - val_acc: 0.8020\n",
            "Epoch 184/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0400 - acc: 0.8500 - val_loss: 0.1504 - val_acc: 0.8020\n",
            "Epoch 185/20000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0413 - acc: 0.8571 - val_loss: 0.1508 - val_acc: 0.7960\n",
            "Epoch 186/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0412 - acc: 0.8643 - val_loss: 0.1510 - val_acc: 0.7940\n",
            "Epoch 187/20000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0356 - acc: 0.8786 - val_loss: 0.1508 - val_acc: 0.7940\n",
            "Epoch 188/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0367 - acc: 0.8929 - val_loss: 0.1502 - val_acc: 0.7940\n",
            "Epoch 189/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0408 - acc: 0.8571 - val_loss: 0.1496 - val_acc: 0.7940\n",
            "Epoch 190/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0417 - acc: 0.8429 - val_loss: 0.1488 - val_acc: 0.7940\n",
            "Epoch 191/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0373 - acc: 0.8571 - val_loss: 0.1480 - val_acc: 0.7940\n",
            "Epoch 192/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0391 - acc: 0.8429 - val_loss: 0.1472 - val_acc: 0.7920\n",
            "Epoch 193/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0423 - acc: 0.8500 - val_loss: 0.1460 - val_acc: 0.7940\n",
            "Epoch 194/20000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0420 - acc: 0.8071 - val_loss: 0.1449 - val_acc: 0.8000\n",
            "Epoch 195/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0429 - acc: 0.8500 - val_loss: 0.1445 - val_acc: 0.8020\n",
            "Epoch 196/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0444 - acc: 0.8143 - val_loss: 0.1443 - val_acc: 0.7980\n",
            "Epoch 197/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0408 - acc: 0.8429 - val_loss: 0.1443 - val_acc: 0.8020\n",
            "Epoch 198/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0403 - acc: 0.8571 - val_loss: 0.1443 - val_acc: 0.8040\n",
            "Epoch 199/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0442 - acc: 0.8286 - val_loss: 0.1442 - val_acc: 0.8020\n",
            "Epoch 200/20000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0353 - acc: 0.8786 - val_loss: 0.1441 - val_acc: 0.8020\n",
            "Epoch 201/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0444 - acc: 0.7929 - val_loss: 0.1439 - val_acc: 0.8040\n",
            "Epoch 202/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0369 - acc: 0.8857 - val_loss: 0.1436 - val_acc: 0.8060\n",
            "Epoch 203/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0417 - acc: 0.8214 - val_loss: 0.1435 - val_acc: 0.8040\n",
            "Epoch 204/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0383 - acc: 0.8357 - val_loss: 0.1437 - val_acc: 0.8040\n",
            "Epoch 205/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0379 - acc: 0.8571 - val_loss: 0.1441 - val_acc: 0.8020\n",
            "Epoch 206/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0393 - acc: 0.8357 - val_loss: 0.1442 - val_acc: 0.7980\n",
            "Epoch 207/20000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0445 - acc: 0.7643 - val_loss: 0.1446 - val_acc: 0.7960\n",
            "Epoch 208/20000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0450 - acc: 0.8143 - val_loss: 0.1449 - val_acc: 0.7960\n",
            "Epoch 209/20000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0431 - acc: 0.8214 - val_loss: 0.1444 - val_acc: 0.7960\n",
            "Epoch 210/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0401 - acc: 0.8357 - val_loss: 0.1439 - val_acc: 0.8040\n",
            "Epoch 211/20000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0372 - acc: 0.8643 - val_loss: 0.1436 - val_acc: 0.7980\n",
            "Epoch 212/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0432 - acc: 0.8500 - val_loss: 0.1434 - val_acc: 0.7980\n",
            "Epoch 213/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0404 - acc: 0.8286 - val_loss: 0.1431 - val_acc: 0.7960\n",
            "Epoch 214/20000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0404 - acc: 0.8286 - val_loss: 0.1430 - val_acc: 0.7960\n",
            "Epoch 215/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0467 - acc: 0.7571 - val_loss: 0.1427 - val_acc: 0.7960\n",
            "Epoch 216/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0457 - acc: 0.7786 - val_loss: 0.1422 - val_acc: 0.7980\n",
            "Epoch 217/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0436 - acc: 0.8286 - val_loss: 0.1419 - val_acc: 0.7960\n",
            "Epoch 218/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0421 - acc: 0.8571 - val_loss: 0.1414 - val_acc: 0.8020\n",
            "Epoch 219/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0387 - acc: 0.8214 - val_loss: 0.1410 - val_acc: 0.8000\n",
            "Epoch 220/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0399 - acc: 0.8429 - val_loss: 0.1404 - val_acc: 0.8040\n",
            "Epoch 221/20000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0412 - acc: 0.8071 - val_loss: 0.1402 - val_acc: 0.8060\n",
            "Epoch 222/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0423 - acc: 0.8214 - val_loss: 0.1403 - val_acc: 0.8020\n",
            "Epoch 223/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0384 - acc: 0.8429 - val_loss: 0.1410 - val_acc: 0.8020\n",
            "Epoch 224/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0426 - acc: 0.8071 - val_loss: 0.1416 - val_acc: 0.7960\n",
            "Epoch 225/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0387 - acc: 0.8143 - val_loss: 0.1420 - val_acc: 0.7960\n",
            "Epoch 226/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0384 - acc: 0.8286 - val_loss: 0.1424 - val_acc: 0.7980\n",
            "Epoch 227/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0398 - acc: 0.8429 - val_loss: 0.1427 - val_acc: 0.8000\n",
            "Epoch 228/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0401 - acc: 0.8071 - val_loss: 0.1430 - val_acc: 0.8000\n",
            "Epoch 229/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0400 - acc: 0.8429 - val_loss: 0.1432 - val_acc: 0.7960\n",
            "Epoch 230/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0388 - acc: 0.8500 - val_loss: 0.1433 - val_acc: 0.7960\n",
            "Epoch 231/20000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0357 - acc: 0.8571 - val_loss: 0.1434 - val_acc: 0.7980\n",
            "Epoch 232/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0417 - acc: 0.8071 - val_loss: 0.1434 - val_acc: 0.7960\n",
            "Epoch 233/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0389 - acc: 0.8286 - val_loss: 0.1435 - val_acc: 0.7960\n",
            "Epoch 234/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0435 - acc: 0.8429 - val_loss: 0.1434 - val_acc: 0.7940\n",
            "Epoch 235/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0362 - acc: 0.8571 - val_loss: 0.1433 - val_acc: 0.7940\n",
            "Epoch 236/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0437 - acc: 0.7714 - val_loss: 0.1431 - val_acc: 0.7940\n",
            "Epoch 237/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0401 - acc: 0.8357 - val_loss: 0.1427 - val_acc: 0.7960\n",
            "Epoch 238/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0354 - acc: 0.8857 - val_loss: 0.1417 - val_acc: 0.7960\n",
            "Epoch 239/20000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0323 - acc: 0.8643 - val_loss: 0.1410 - val_acc: 0.7960\n",
            "Epoch 240/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0336 - acc: 0.8786 - val_loss: 0.1404 - val_acc: 0.8000\n",
            "Epoch 241/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0383 - acc: 0.8571 - val_loss: 0.1397 - val_acc: 0.8040\n",
            "Epoch 242/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0373 - acc: 0.8714 - val_loss: 0.1392 - val_acc: 0.8040\n",
            "Epoch 243/20000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0381 - acc: 0.8500 - val_loss: 0.1388 - val_acc: 0.8040\n",
            "Epoch 244/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0453 - acc: 0.7929 - val_loss: 0.1383 - val_acc: 0.8080\n",
            "Epoch 245/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0388 - acc: 0.8500 - val_loss: 0.1377 - val_acc: 0.8080\n",
            "Epoch 246/20000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0379 - acc: 0.8429 - val_loss: 0.1373 - val_acc: 0.8080\n",
            "Epoch 247/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0359 - acc: 0.8286 - val_loss: 0.1368 - val_acc: 0.8020\n",
            "Epoch 248/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0345 - acc: 0.8786 - val_loss: 0.1362 - val_acc: 0.8060\n",
            "Epoch 249/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0373 - acc: 0.8286 - val_loss: 0.1358 - val_acc: 0.8080\n",
            "Epoch 250/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0323 - acc: 0.9000 - val_loss: 0.1354 - val_acc: 0.8080\n",
            "Epoch 251/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0358 - acc: 0.8786 - val_loss: 0.1352 - val_acc: 0.8080\n",
            "Epoch 252/20000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0421 - acc: 0.8286 - val_loss: 0.1351 - val_acc: 0.8120\n",
            "Epoch 253/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0406 - acc: 0.8214 - val_loss: 0.1349 - val_acc: 0.8140\n",
            "Epoch 254/20000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0407 - acc: 0.8429 - val_loss: 0.1352 - val_acc: 0.8120\n",
            "Epoch 255/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0366 - acc: 0.8286 - val_loss: 0.1356 - val_acc: 0.8120\n",
            "Epoch 256/20000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0365 - acc: 0.8571 - val_loss: 0.1362 - val_acc: 0.8120\n",
            "Epoch 257/20000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0357 - acc: 0.8429 - val_loss: 0.1370 - val_acc: 0.8100\n",
            "Epoch 258/20000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0389 - acc: 0.8286 - val_loss: 0.1376 - val_acc: 0.8080\n",
            "Epoch 259/20000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0365 - acc: 0.8786 - val_loss: 0.1381 - val_acc: 0.8020\n",
            "Epoch 260/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0444 - acc: 0.8143 - val_loss: 0.1383 - val_acc: 0.7940\n",
            "Epoch 261/20000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0407 - acc: 0.8214 - val_loss: 0.1383 - val_acc: 0.7940\n",
            "Epoch 262/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0410 - acc: 0.7929 - val_loss: 0.1386 - val_acc: 0.7920\n",
            "Epoch 263/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0420 - acc: 0.7857 - val_loss: 0.1384 - val_acc: 0.7960\n",
            "Epoch 264/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0370 - acc: 0.8214 - val_loss: 0.1382 - val_acc: 0.7980\n",
            "Epoch 265/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0378 - acc: 0.8286 - val_loss: 0.1381 - val_acc: 0.8000\n",
            "Epoch 266/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0407 - acc: 0.8429 - val_loss: 0.1383 - val_acc: 0.8000\n",
            "Epoch 267/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0397 - acc: 0.8143 - val_loss: 0.1389 - val_acc: 0.8000\n",
            "Epoch 268/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0348 - acc: 0.8357 - val_loss: 0.1390 - val_acc: 0.8000\n",
            "Epoch 269/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0372 - acc: 0.8500 - val_loss: 0.1390 - val_acc: 0.8000\n",
            "Epoch 270/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0372 - acc: 0.8214 - val_loss: 0.1388 - val_acc: 0.7980\n",
            "Epoch 271/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0379 - acc: 0.8571 - val_loss: 0.1386 - val_acc: 0.8000\n",
            "Epoch 272/20000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0396 - acc: 0.8429 - val_loss: 0.1388 - val_acc: 0.8000\n",
            "Epoch 273/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0381 - acc: 0.8714 - val_loss: 0.1391 - val_acc: 0.7980\n",
            "Epoch 274/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0336 - acc: 0.8714 - val_loss: 0.1392 - val_acc: 0.8000\n",
            "Epoch 275/20000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0361 - acc: 0.8643 - val_loss: 0.1393 - val_acc: 0.8000\n",
            "Epoch 276/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0366 - acc: 0.8714 - val_loss: 0.1391 - val_acc: 0.8020\n",
            "Epoch 277/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0349 - acc: 0.8500 - val_loss: 0.1391 - val_acc: 0.8000\n",
            "Epoch 278/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0360 - acc: 0.8643 - val_loss: 0.1391 - val_acc: 0.8000\n",
            "Epoch 279/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0366 - acc: 0.8500 - val_loss: 0.1395 - val_acc: 0.8000\n",
            "Epoch 280/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0345 - acc: 0.8714 - val_loss: 0.1402 - val_acc: 0.7980\n",
            "Epoch 281/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0384 - acc: 0.8571 - val_loss: 0.1409 - val_acc: 0.7960\n",
            "Epoch 282/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0392 - acc: 0.8286 - val_loss: 0.1413 - val_acc: 0.7940\n",
            "Epoch 283/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0390 - acc: 0.8286 - val_loss: 0.1420 - val_acc: 0.7920\n",
            "Epoch 284/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0388 - acc: 0.8286 - val_loss: 0.1418 - val_acc: 0.7920\n",
            "Epoch 285/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0366 - acc: 0.8643 - val_loss: 0.1417 - val_acc: 0.7920\n",
            "Epoch 286/20000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0441 - acc: 0.7786 - val_loss: 0.1413 - val_acc: 0.7900\n",
            "Epoch 287/20000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0366 - acc: 0.8571 - val_loss: 0.1401 - val_acc: 0.7920\n",
            "Epoch 288/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0374 - acc: 0.8286 - val_loss: 0.1383 - val_acc: 0.7920\n",
            "Epoch 289/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0367 - acc: 0.8500 - val_loss: 0.1364 - val_acc: 0.7960\n",
            "Epoch 290/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0336 - acc: 0.8714 - val_loss: 0.1348 - val_acc: 0.7980\n",
            "Epoch 291/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0358 - acc: 0.8500 - val_loss: 0.1335 - val_acc: 0.8000\n",
            "Epoch 292/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0327 - acc: 0.9071 - val_loss: 0.1328 - val_acc: 0.8040\n",
            "Epoch 293/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0388 - acc: 0.8429 - val_loss: 0.1324 - val_acc: 0.8040\n",
            "Epoch 294/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0363 - acc: 0.8571 - val_loss: 0.1324 - val_acc: 0.8020\n",
            "Epoch 295/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0431 - acc: 0.8071 - val_loss: 0.1329 - val_acc: 0.8000\n",
            "Epoch 296/20000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0375 - acc: 0.8286 - val_loss: 0.1332 - val_acc: 0.8000\n",
            "Epoch 297/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0436 - acc: 0.8071 - val_loss: 0.1342 - val_acc: 0.8000\n",
            "Epoch 298/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0325 - acc: 0.8714 - val_loss: 0.1350 - val_acc: 0.7960\n",
            "Epoch 299/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0416 - acc: 0.8143 - val_loss: 0.1354 - val_acc: 0.8000\n",
            "Epoch 300/20000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0399 - acc: 0.8357 - val_loss: 0.1358 - val_acc: 0.7980\n",
            "Epoch 301/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0402 - acc: 0.8286 - val_loss: 0.1361 - val_acc: 0.8000\n",
            "Epoch 302/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0380 - acc: 0.8500 - val_loss: 0.1360 - val_acc: 0.7920\n",
            "Epoch 303/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0376 - acc: 0.8214 - val_loss: 0.1361 - val_acc: 0.7900\n",
            "Epoch 304/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0382 - acc: 0.8429 - val_loss: 0.1365 - val_acc: 0.7900\n",
            "Epoch 305/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0419 - acc: 0.8071 - val_loss: 0.1363 - val_acc: 0.7900\n",
            "Epoch 306/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0348 - acc: 0.8429 - val_loss: 0.1360 - val_acc: 0.7940\n",
            "Epoch 307/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0377 - acc: 0.8429 - val_loss: 0.1357 - val_acc: 0.7980\n",
            "Epoch 308/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0372 - acc: 0.8643 - val_loss: 0.1355 - val_acc: 0.8000\n",
            "Epoch 309/20000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0421 - acc: 0.8071 - val_loss: 0.1354 - val_acc: 0.7980\n",
            "Epoch 310/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0353 - acc: 0.8929 - val_loss: 0.1355 - val_acc: 0.7940\n",
            "Epoch 311/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0406 - acc: 0.8071 - val_loss: 0.1360 - val_acc: 0.7960\n",
            "Epoch 312/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0363 - acc: 0.8286 - val_loss: 0.1364 - val_acc: 0.7960\n",
            "Epoch 313/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0400 - acc: 0.8000 - val_loss: 0.1371 - val_acc: 0.7980\n",
            "Epoch 314/20000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0390 - acc: 0.7929 - val_loss: 0.1374 - val_acc: 0.8000\n",
            "Epoch 315/20000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0372 - acc: 0.8429 - val_loss: 0.1378 - val_acc: 0.7940\n",
            "Epoch 316/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0433 - acc: 0.7786 - val_loss: 0.1378 - val_acc: 0.7900\n",
            "Epoch 317/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0367 - acc: 0.8714 - val_loss: 0.1380 - val_acc: 0.7880\n",
            "Epoch 318/20000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0388 - acc: 0.8357 - val_loss: 0.1378 - val_acc: 0.7900\n",
            "Epoch 319/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0383 - acc: 0.8429 - val_loss: 0.1375 - val_acc: 0.7900\n",
            "Epoch 320/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0395 - acc: 0.8143 - val_loss: 0.1371 - val_acc: 0.7960\n",
            "Epoch 321/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0342 - acc: 0.8714 - val_loss: 0.1365 - val_acc: 0.7980\n",
            "Epoch 322/20000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0341 - acc: 0.8929 - val_loss: 0.1359 - val_acc: 0.7980\n",
            "Epoch 323/20000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0343 - acc: 0.8786 - val_loss: 0.1354 - val_acc: 0.8000\n",
            "Epoch 324/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0359 - acc: 0.8571 - val_loss: 0.1350 - val_acc: 0.8000\n",
            "Epoch 325/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0348 - acc: 0.8357 - val_loss: 0.1348 - val_acc: 0.8000\n",
            "Epoch 326/20000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0372 - acc: 0.8357 - val_loss: 0.1346 - val_acc: 0.7960\n",
            "Epoch 327/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0354 - acc: 0.8571 - val_loss: 0.1342 - val_acc: 0.7980\n",
            "Epoch 328/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0348 - acc: 0.8857 - val_loss: 0.1340 - val_acc: 0.7980\n",
            "Epoch 329/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0367 - acc: 0.8429 - val_loss: 0.1336 - val_acc: 0.7940\n",
            "Epoch 330/20000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0346 - acc: 0.8714 - val_loss: 0.1331 - val_acc: 0.7940\n",
            "Epoch 331/20000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0389 - acc: 0.8143 - val_loss: 0.1330 - val_acc: 0.7940\n",
            "Epoch 332/20000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0362 - acc: 0.8429 - val_loss: 0.1329 - val_acc: 0.7960\n",
            "Epoch 333/20000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0376 - acc: 0.8429 - val_loss: 0.1327 - val_acc: 0.7980\n",
            "Epoch 334/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0318 - acc: 0.8929 - val_loss: 0.1324 - val_acc: 0.8000\n",
            "Epoch 335/20000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0404 - acc: 0.7857 - val_loss: 0.1323 - val_acc: 0.8020\n",
            "Epoch 336/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0278 - acc: 0.9214 - val_loss: 0.1321 - val_acc: 0.8060\n",
            "Epoch 337/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0363 - acc: 0.8357 - val_loss: 0.1319 - val_acc: 0.8040\n",
            "Epoch 338/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0339 - acc: 0.8429 - val_loss: 0.1317 - val_acc: 0.8020\n",
            "Epoch 339/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0342 - acc: 0.8857 - val_loss: 0.1317 - val_acc: 0.8000\n",
            "Epoch 340/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0406 - acc: 0.8214 - val_loss: 0.1321 - val_acc: 0.8000\n",
            "Epoch 341/20000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0405 - acc: 0.8214 - val_loss: 0.1324 - val_acc: 0.8000\n",
            "Epoch 342/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0359 - acc: 0.8357 - val_loss: 0.1329 - val_acc: 0.8000\n",
            "Epoch 343/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0346 - acc: 0.8714 - val_loss: 0.1332 - val_acc: 0.8020\n",
            "Epoch 344/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0370 - acc: 0.8571 - val_loss: 0.1337 - val_acc: 0.8020\n",
            "Epoch 345/20000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0423 - acc: 0.7857 - val_loss: 0.1341 - val_acc: 0.8020\n",
            "Epoch 346/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0375 - acc: 0.8571 - val_loss: 0.1337 - val_acc: 0.8000\n",
            "Epoch 347/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0367 - acc: 0.8286 - val_loss: 0.1333 - val_acc: 0.8040\n",
            "Epoch 348/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0342 - acc: 0.8714 - val_loss: 0.1331 - val_acc: 0.8080\n",
            "Epoch 349/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0369 - acc: 0.8429 - val_loss: 0.1330 - val_acc: 0.8040\n",
            "Epoch 350/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0351 - acc: 0.8571 - val_loss: 0.1330 - val_acc: 0.8040\n",
            "Epoch 351/20000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0391 - acc: 0.8571 - val_loss: 0.1331 - val_acc: 0.8040\n",
            "Epoch 352/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0352 - acc: 0.8429 - val_loss: 0.1331 - val_acc: 0.8040\n",
            "Epoch 353/20000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0367 - acc: 0.8429 - val_loss: 0.1330 - val_acc: 0.8040\n",
            "Epoch 354/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0338 - acc: 0.8571 - val_loss: 0.1326 - val_acc: 0.8000\n",
            "Epoch 355/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0417 - acc: 0.8286 - val_loss: 0.1323 - val_acc: 0.8000\n",
            "Epoch 356/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0347 - acc: 0.8786 - val_loss: 0.1318 - val_acc: 0.8000\n",
            "Epoch 357/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0346 - acc: 0.8857 - val_loss: 0.1318 - val_acc: 0.8000\n",
            "Epoch 358/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0298 - acc: 0.9071 - val_loss: 0.1319 - val_acc: 0.7980\n",
            "Epoch 359/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0365 - acc: 0.8357 - val_loss: 0.1323 - val_acc: 0.7980\n",
            "Epoch 360/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0365 - acc: 0.8500 - val_loss: 0.1325 - val_acc: 0.7980\n",
            "Epoch 361/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0387 - acc: 0.8286 - val_loss: 0.1326 - val_acc: 0.7980\n",
            "Epoch 362/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0360 - acc: 0.8714 - val_loss: 0.1328 - val_acc: 0.7980\n",
            "Epoch 363/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0372 - acc: 0.8214 - val_loss: 0.1330 - val_acc: 0.8000\n",
            "Epoch 364/20000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0422 - acc: 0.7929 - val_loss: 0.1331 - val_acc: 0.8000\n",
            "Epoch 365/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0377 - acc: 0.8357 - val_loss: 0.1326 - val_acc: 0.8000\n",
            "Epoch 366/20000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0390 - acc: 0.8429 - val_loss: 0.1320 - val_acc: 0.8000\n",
            "Epoch 367/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0357 - acc: 0.8357 - val_loss: 0.1314 - val_acc: 0.7980\n",
            "Epoch 368/20000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0365 - acc: 0.8643 - val_loss: 0.1305 - val_acc: 0.7980\n",
            "Epoch 369/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0352 - acc: 0.8571 - val_loss: 0.1298 - val_acc: 0.8000\n",
            "Epoch 370/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0346 - acc: 0.8571 - val_loss: 0.1291 - val_acc: 0.8040\n",
            "Epoch 371/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0389 - acc: 0.8214 - val_loss: 0.1289 - val_acc: 0.8060\n",
            "Epoch 372/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0379 - acc: 0.8571 - val_loss: 0.1293 - val_acc: 0.8040\n",
            "Epoch 373/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0404 - acc: 0.8000 - val_loss: 0.1297 - val_acc: 0.8020\n",
            "Epoch 374/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0357 - acc: 0.8571 - val_loss: 0.1307 - val_acc: 0.8000\n",
            "Epoch 375/20000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0344 - acc: 0.8500 - val_loss: 0.1318 - val_acc: 0.7980\n",
            "Epoch 376/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0350 - acc: 0.8714 - val_loss: 0.1328 - val_acc: 0.7940\n",
            "Epoch 377/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0400 - acc: 0.8286 - val_loss: 0.1333 - val_acc: 0.7940\n",
            "Epoch 378/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0389 - acc: 0.8286 - val_loss: 0.1337 - val_acc: 0.7920\n",
            "Epoch 379/20000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0371 - acc: 0.8786 - val_loss: 0.1342 - val_acc: 0.7940\n",
            "Epoch 380/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0391 - acc: 0.8357 - val_loss: 0.1345 - val_acc: 0.7980\n",
            "Epoch 381/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0354 - acc: 0.8857 - val_loss: 0.1346 - val_acc: 0.7980\n",
            "Epoch 382/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0348 - acc: 0.8429 - val_loss: 0.1345 - val_acc: 0.7980\n",
            "Epoch 383/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0333 - acc: 0.9000 - val_loss: 0.1344 - val_acc: 0.8000\n",
            "Epoch 384/20000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0377 - acc: 0.8643 - val_loss: 0.1348 - val_acc: 0.8020\n",
            "Epoch 385/20000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0359 - acc: 0.8571 - val_loss: 0.1351 - val_acc: 0.8000\n",
            "Epoch 386/20000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0364 - acc: 0.8643 - val_loss: 0.1351 - val_acc: 0.8000\n",
            "Epoch 387/20000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0388 - acc: 0.8071 - val_loss: 0.1350 - val_acc: 0.7980\n",
            "Epoch 388/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0343 - acc: 0.8571 - val_loss: 0.1351 - val_acc: 0.7960\n",
            "Epoch 389/20000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0407 - acc: 0.8500 - val_loss: 0.1352 - val_acc: 0.7980\n",
            "Epoch 390/20000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0359 - acc: 0.8357 - val_loss: 0.1348 - val_acc: 0.7980\n",
            "Epoch 391/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0359 - acc: 0.8429 - val_loss: 0.1346 - val_acc: 0.8000\n",
            "Epoch 392/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0353 - acc: 0.8643 - val_loss: 0.1341 - val_acc: 0.8000\n",
            "Epoch 393/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0353 - acc: 0.8286 - val_loss: 0.1333 - val_acc: 0.7980\n",
            "Epoch 394/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0332 - acc: 0.8714 - val_loss: 0.1329 - val_acc: 0.7960\n",
            "Epoch 395/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0365 - acc: 0.8429 - val_loss: 0.1325 - val_acc: 0.7960\n",
            "Epoch 396/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0348 - acc: 0.8643 - val_loss: 0.1325 - val_acc: 0.7960\n",
            "Epoch 397/20000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0322 - acc: 0.8857 - val_loss: 0.1325 - val_acc: 0.7980\n",
            "Epoch 398/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0378 - acc: 0.8214 - val_loss: 0.1323 - val_acc: 0.8000\n",
            "Epoch 399/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0347 - acc: 0.8643 - val_loss: 0.1323 - val_acc: 0.7980\n",
            "Epoch 400/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0345 - acc: 0.8714 - val_loss: 0.1326 - val_acc: 0.7960\n",
            "Epoch 401/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0361 - acc: 0.8714 - val_loss: 0.1330 - val_acc: 0.7940\n",
            "Epoch 402/20000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0324 - acc: 0.8857 - val_loss: 0.1338 - val_acc: 0.7940\n",
            "Epoch 403/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0367 - acc: 0.8286 - val_loss: 0.1345 - val_acc: 0.7900\n",
            "Epoch 404/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0357 - acc: 0.8500 - val_loss: 0.1344 - val_acc: 0.7940\n",
            "Epoch 405/20000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0394 - acc: 0.8286 - val_loss: 0.1345 - val_acc: 0.7920\n",
            "Epoch 406/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0332 - acc: 0.8643 - val_loss: 0.1349 - val_acc: 0.7900\n",
            "Epoch 407/20000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0372 - acc: 0.8214 - val_loss: 0.1350 - val_acc: 0.7940\n",
            "Epoch 408/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0370 - acc: 0.8571 - val_loss: 0.1349 - val_acc: 0.7880\n",
            "Epoch 409/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0347 - acc: 0.8643 - val_loss: 0.1343 - val_acc: 0.7900\n",
            "Epoch 410/20000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0341 - acc: 0.8357 - val_loss: 0.1337 - val_acc: 0.7900\n",
            "Epoch 411/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0397 - acc: 0.8143 - val_loss: 0.1328 - val_acc: 0.7920\n",
            "Epoch 412/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0338 - acc: 0.8714 - val_loss: 0.1319 - val_acc: 0.7900\n",
            "Epoch 413/20000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0347 - acc: 0.8714 - val_loss: 0.1309 - val_acc: 0.7980\n",
            "Epoch 414/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0361 - acc: 0.8500 - val_loss: 0.1299 - val_acc: 0.7940\n",
            "Epoch 415/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0373 - acc: 0.8286 - val_loss: 0.1290 - val_acc: 0.7960\n",
            "Epoch 416/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0367 - acc: 0.8357 - val_loss: 0.1292 - val_acc: 0.7980\n",
            "Epoch 417/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0317 - acc: 0.8929 - val_loss: 0.1292 - val_acc: 0.8020\n",
            "Epoch 418/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0378 - acc: 0.8643 - val_loss: 0.1294 - val_acc: 0.8020\n",
            "Epoch 419/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0367 - acc: 0.8286 - val_loss: 0.1295 - val_acc: 0.8020\n",
            "Epoch 420/20000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0359 - acc: 0.8286 - val_loss: 0.1298 - val_acc: 0.8000\n",
            "Epoch 421/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0293 - acc: 0.9143 - val_loss: 0.1303 - val_acc: 0.8000\n",
            "Epoch 422/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0381 - acc: 0.8214 - val_loss: 0.1310 - val_acc: 0.7980\n",
            "Epoch 423/20000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0364 - acc: 0.8429 - val_loss: 0.1317 - val_acc: 0.8000\n",
            "Epoch 424/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0404 - acc: 0.8286 - val_loss: 0.1322 - val_acc: 0.7980\n",
            "Epoch 425/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0340 - acc: 0.8357 - val_loss: 0.1331 - val_acc: 0.7960\n",
            "Epoch 426/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0346 - acc: 0.9000 - val_loss: 0.1341 - val_acc: 0.7900\n",
            "Epoch 427/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0364 - acc: 0.8286 - val_loss: 0.1351 - val_acc: 0.7900\n",
            "Epoch 428/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0354 - acc: 0.8643 - val_loss: 0.1360 - val_acc: 0.7920\n",
            "Epoch 429/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0337 - acc: 0.8714 - val_loss: 0.1363 - val_acc: 0.7920\n",
            "Epoch 430/20000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0334 - acc: 0.8643 - val_loss: 0.1362 - val_acc: 0.7900\n",
            "Epoch 431/20000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0392 - acc: 0.8000 - val_loss: 0.1359 - val_acc: 0.7880\n",
            "Epoch 432/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0388 - acc: 0.8143 - val_loss: 0.1352 - val_acc: 0.7900\n",
            "Epoch 433/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0379 - acc: 0.8429 - val_loss: 0.1347 - val_acc: 0.7900\n",
            "Epoch 434/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0340 - acc: 0.8643 - val_loss: 0.1340 - val_acc: 0.7880\n",
            "Epoch 435/20000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0361 - acc: 0.8500 - val_loss: 0.1333 - val_acc: 0.7960\n",
            "Epoch 436/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0353 - acc: 0.8643 - val_loss: 0.1323 - val_acc: 0.8020\n",
            "Epoch 437/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0373 - acc: 0.8429 - val_loss: 0.1315 - val_acc: 0.8020\n",
            "Epoch 438/20000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0354 - acc: 0.8643 - val_loss: 0.1313 - val_acc: 0.8000\n",
            "Epoch 439/20000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0328 - acc: 0.8786 - val_loss: 0.1309 - val_acc: 0.7980\n",
            "Epoch 440/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0372 - acc: 0.8429 - val_loss: 0.1306 - val_acc: 0.7980\n",
            "Epoch 441/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0381 - acc: 0.8429 - val_loss: 0.1305 - val_acc: 0.7960\n",
            "Epoch 442/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0367 - acc: 0.8357 - val_loss: 0.1304 - val_acc: 0.7960\n",
            "Epoch 443/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0362 - acc: 0.8357 - val_loss: 0.1304 - val_acc: 0.7960\n",
            "Epoch 444/20000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0361 - acc: 0.8429 - val_loss: 0.1305 - val_acc: 0.7960\n",
            "Epoch 445/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0330 - acc: 0.8571 - val_loss: 0.1302 - val_acc: 0.7920\n",
            "Epoch 446/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0381 - acc: 0.8500 - val_loss: 0.1303 - val_acc: 0.7920\n",
            "Epoch 447/20000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0354 - acc: 0.8500 - val_loss: 0.1306 - val_acc: 0.7960\n",
            "Epoch 448/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0403 - acc: 0.8143 - val_loss: 0.1310 - val_acc: 0.7960\n",
            "Epoch 449/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0344 - acc: 0.8786 - val_loss: 0.1313 - val_acc: 0.7960\n",
            "Epoch 450/20000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0324 - acc: 0.9000 - val_loss: 0.1319 - val_acc: 0.7960\n",
            "Epoch 451/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0342 - acc: 0.8643 - val_loss: 0.1319 - val_acc: 0.7960\n",
            "Epoch 452/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0344 - acc: 0.8571 - val_loss: 0.1318 - val_acc: 0.7960\n",
            "Epoch 453/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0425 - acc: 0.7929 - val_loss: 0.1317 - val_acc: 0.7960\n",
            "Epoch 454/20000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0298 - acc: 0.9214 - val_loss: 0.1319 - val_acc: 0.7960\n",
            "Epoch 455/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0364 - acc: 0.8429 - val_loss: 0.1320 - val_acc: 0.7960\n",
            "Epoch 456/20000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0338 - acc: 0.8500 - val_loss: 0.1322 - val_acc: 0.7980\n",
            "Epoch 457/20000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0337 - acc: 0.8786 - val_loss: 0.1330 - val_acc: 0.7980\n",
            "Epoch 458/20000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0348 - acc: 0.8643 - val_loss: 0.1341 - val_acc: 0.8000\n",
            "Epoch 459/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0344 - acc: 0.8429 - val_loss: 0.1349 - val_acc: 0.7980\n",
            "Epoch 460/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0369 - acc: 0.8214 - val_loss: 0.1351 - val_acc: 0.7960\n",
            "Epoch 461/20000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0349 - acc: 0.8500 - val_loss: 0.1351 - val_acc: 0.7920\n",
            "Epoch 462/20000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0314 - acc: 0.8786 - val_loss: 0.1351 - val_acc: 0.7920\n",
            "Epoch 463/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0332 - acc: 0.8714 - val_loss: 0.1347 - val_acc: 0.7900\n",
            "Epoch 464/20000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0349 - acc: 0.8571 - val_loss: 0.1343 - val_acc: 0.7920\n",
            "Epoch 465/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0417 - acc: 0.8000 - val_loss: 0.1345 - val_acc: 0.7920\n",
            "Epoch 466/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0402 - acc: 0.8143 - val_loss: 0.1345 - val_acc: 0.7920\n",
            "Epoch 467/20000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0372 - acc: 0.8357 - val_loss: 0.1347 - val_acc: 0.7920\n",
            "Epoch 468/20000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0330 - acc: 0.8714 - val_loss: 0.1345 - val_acc: 0.7940\n",
            "Epoch 469/20000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0361 - acc: 0.8214 - val_loss: 0.1341 - val_acc: 0.7920\n",
            "Epoch 470/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0322 - acc: 0.8786 - val_loss: 0.1332 - val_acc: 0.7920\n",
            "Epoch 471/20000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0344 - acc: 0.8500 - val_loss: 0.1326 - val_acc: 0.7940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9f52c06c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9_NyXd4U7U8",
        "outputId": "4eb7890c-b097-4ce6-dc43-91006aec197d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate model\n",
        "print('Evaluating model.')\n",
        "eval_results = model.evaluate([X, A],\n",
        "                              y,\n",
        "                              sample_weight=test_mask,\n",
        "                              batch_size=N)\n",
        "print('Done.\\n'\n",
        "      'Test loss: {}\\n'\n",
        "      'Test accuracy: {}'.format(*eval_results))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating model.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2290 - acc: 0.8350\n",
            "Done.\n",
            "Test loss: 0.22903212904930115\n",
            "Test accuracy: 0.8349999785423279\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}